{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KYvD5dGmnWbSwJldHl_dK86O-WW9nz4m","timestamp":1670789111953},{"file_id":"1ioyp9OX4H9wa1zO9EvdAr4N7CEMyeMP6","timestamp":1669889176516}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["Due Date: December 11th"],"metadata":{"id":"F3ZF3oYIJ3KW"}},{"cell_type":"markdown","metadata":{"id":"YzptQhdh0pUr"},"source":["# Vaccine Development with Dynamic Programming\n","\n","You are the CEO of a biotech company which is considering the development of a new vaccine. Starting at phase 0 (state 0), the drug develpment can stay in the same state or advance to \"phase 1  with promising results\" (state 1) or advance to \"phase 1 with disappointing results\" (state 2), or fail completely (state 4). At phase 1, the drug can stay in the same state, fail or become a success (state 3), in which case you will sell its patent to a big pharma company for \\$10 million.\n","These state transitions happen from month to month, and at each state, you have the option to make an additional investment of \\$100,000, which increases the chances of success.\n","\n","After careful study, your analysts develop the program below to simulate different scenarios using statistical data from similar projects. \n","\n","Use a discount factor of 0.996.\n","\n","- 1) Write a policy iteration algorithm to compute the value of this project. Please print the full V vector.\n","\n","- 2 )Write a value iteration algorithm to compute the value of this project. Please print the full V vector."]},{"cell_type":"code","metadata":{"id":"dnAvrShs6ecs","executionInfo":{"status":"ok","timestamp":1670804924668,"user_tz":360,"elapsed":130,"user":{"displayName":"vineeth kotala","userId":"18129638174199106193"}}},"source":["import numpy as np\n","class MDP():\n","  def __init__(self):\n","    # Discount factor\n","    self.γ = 0.95\n","    self.A = [0, 1]\n","    self.S = [0, 1, 2, 3, 4]\n","\n","    # Transition matrix if dont' invest\n","    P0 = np.array([[0.5, .15, .15, 0, .20],\n","                   [0, .5, .0, .25, .25],\n","                   [0, 0, .15, .05, .8],\n","                   [0, 0, 0, 0, 1],\n","                   [0, 0, 0, 0, 1]])\n","\n","    R0 = np.array([0, 0, 0, 10, 0])\n","\n","    # Transition matrix if invest\n","    P1 = np.array([[0.5, .25, .15, 0, .10],\n","                   [0, .5, .0, .35, .15],\n","                   [0, 0, .20, .05, .75],\n","                   [0, 0, 0, 0, 1],\n","                   [0, 0, 0, 0, 1]])\n","\n","    R1 = np.array([-0.1, -0.1, -0.1, 10, 0])\n","\n","    self.P = [P0, P1]\n","    self.R = [R0, R1]\n","\n","  def step(self, s, a):\n","    s_prime = np.random.choice(len(self.S), p=self.P[a][s])\n","    R = self.R[a][s]\n","    if s_prime == 4:\n","      done = True\n","    else:\n","      done = False\n","    return s_prime, R, done\n","\n","  def simulate(self, s, a, π):\n","    done = False\n","    t = 0\n","    history = []\n","    while not done:\n","      if t > 0:\n","        a = π[s]\n","      s_prime, R, done = self.step(s, a)\n","      history.append((s, a, R))\n","      s = s_prime\n","      t += 1\n","\n","    return history"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["You can access the transition probability matrices and the reward vector as follows:"],"metadata":{"id":"xgAiJxSnZtkH"}},{"cell_type":"code","metadata":{"id":"5-rfjh_37kmX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670804927904,"user_tz":360,"elapsed":141,"user":{"displayName":"vineeth kotala","userId":"18129638174199106193"}},"outputId":"ff36de87-7e5c-42e5-9f2d-faf72d768456"},"source":["mdp = MDP()\n","P = mdp.P\n","R = mdp.R\n","\n","γ = 0.996\n","s = 2 # current state\n","s_prime = 4  # next state\n","a = 1  # chosen action\n","\n","# Probability of transition from state s (2) to s_prime (4) if action == a (1):\n","print(P[a][s, s_prime])\n","\n","# Reward at state s if action = a\n","print(R[a][s])"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["0.75\n","-0.1\n"]}]},{"cell_type":"code","metadata":{"id":"pWfK-47V8I08","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670805234976,"user_tz":360,"elapsed":369,"user":{"displayName":"vineeth kotala","userId":"18129638174199106193"}},"outputId":"4e5d41c2-9383-4a9c-d18b-a18462d2888d"},"source":["import numpy as np\n","\n","\n","def problem_Rπ(R,π,S):\n","  Rπ = np.zeros(len(S))\n","  for s in S:\n","    Rπ[s] = R[π[s]][s]\n","  return Rπ\n","\n","## defining wrt Pπ considering states\n","def problem_Pπ(P,π,S):\n","  Pπ =np.zeros((len(S),len(S)))\n","  for s in S:\n","    for s_prime in S:\n","      Pπ[s,s_prime] = P[π[s]][s,s_prime]\n","  return Pπ\n","\n","π = [0,0,0,0,0]\n","Vπ = np.zeros(5)\n","\n","## Policy evaluation part\n","def policy_eval(π, Vπ):\n","  Rπ = problem_Rπ(R, π, mdp.S)\n","  Pπ = problem_Pπ(P, π, mdp.S)\n","  for iteration in range(1):\n","    Vπ = Rπ + γ * Pπ @ Vπ\n","  return Vπ\n","\n","## Policy improvement part \n","def policy_improve(Vπ):\n","  ## Computing Qπ using Vπ\n","  Qπ = np.zeros((5, 2))\n","  π_prime = np.zeros(5, dtype=np.int32)\n","  for s in mdp.S:\n","    for a in mdp.A:\n","      Qπ[s, a] = R[a][s] + γ * P[a][s] @ Vπ\n","\n","  for s in mdp.S:\n","    π_prime[s] = np.argmax(Qπ[s, :])\n","  return π_prime\n","\n","## Iterating over \n","for iteration in range(100):\n","  Vπ = policy_eval(π, Vπ)\n","  π = policy_improve(Vπ)\n","\n","##Vπ Output\n","Vπ\n","\n"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 3.32067538,  6.74501992,  0.58546908, 10.        ,  0.        ])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["x0 = np.zeros(5)\n","\n","### Defining update and iterating mdp.S\n","def update(x0):\n","  x1 = np.zeros_like(x0)\n","  for s in mdp.S:\n","    x1[s] = np.max([R[a][s] + γ * P[a][s] @ x0 for a in mdp.A])\n","  return x1\n","\n","\n","## Updating values and checking for the error term\n","for _ in range(2000):\n","  x1 = update(x0)\n","  error = np.abs(x0 - x1).max()\n","  if error < 1e-10:\n","    break\n","  x0 = x1\n","\n","## Result\n","x0"],"metadata":{"id":"Zagv6dCFtUsn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670805237617,"user_tz":360,"elapsed":153,"user":{"displayName":"vineeth kotala","userId":"18129638174199106193"}},"outputId":"e967b95d-e604-4430-88e7-dd3686984a6c"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 3.32067538,  6.74501992,  0.58546908, 10.        ,  0.        ])"]},"metadata":{},"execution_count":17}]}]}